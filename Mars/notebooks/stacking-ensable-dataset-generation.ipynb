{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10140426,"sourceType":"datasetVersion","datasetId":6258631}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install segmentation_models_pytorch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T19:52:02.216919Z","iopub.execute_input":"2024-12-14T19:52:02.217241Z","iopub.status.idle":"2024-12-14T19:52:10.598939Z","shell.execute_reply.started":"2024-12-14T19:52:02.217202Z","shell.execute_reply":"2024-12-14T19:52:10.597646Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: segmentation_models_pytorch in /opt/conda/lib/python3.10/site-packages (0.3.4)\nRequirement already satisfied: efficientnet-pytorch==0.7.1 in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (0.7.1)\nRequirement already satisfied: huggingface-hub>=0.24.6 in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (0.26.2)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (10.3.0)\nRequirement already satisfied: pretrainedmodels==0.7.4 in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (0.7.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (1.16.0)\nRequirement already satisfied: timm==0.9.7 in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (0.9.7)\nRequirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (0.19.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (4.66.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.4.0)\nRequirement already satisfied: munch in /opt/conda/lib/python3.10/site-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (4.0.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.9.7->segmentation_models_pytorch) (6.0.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.7->segmentation_models_pytorch) (0.4.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation_models_pytorch) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation_models_pytorch) (2024.6.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation_models_pytorch) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation_models_pytorch) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation_models_pytorch) (4.12.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.26.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.24.6->segmentation_models_pytorch) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation_models_pytorch) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation_models_pytorch) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation_models_pytorch) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation_models_pytorch) (2024.6.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Importing the libraries\nimport matplotlib.pyplot as plt\nimport os\nimport numpy as np\nimport cv2\n\n# Import segmentation_models_pytorch as smp\nimport math\nimport torch\nfrom torch.utils.data import DataLoader, Subset, distributed, Dataset\n\nfrom typing import Dict, List\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom tqdm import tqdm\n\nimport segmentation_models_pytorch as smp","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T19:52:19.534368Z","iopub.execute_input":"2024-12-14T19:52:19.535039Z","iopub.status.idle":"2024-12-14T19:52:26.586303Z","shell.execute_reply.started":"2024-12-14T19:52:19.535005Z","shell.execute_reply":"2024-12-14T19:52:26.585592Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"print('GPU available' if torch.cuda.is_available() else 'GPU not available')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T19:52:37.104138Z","iopub.execute_input":"2024-12-14T19:52:37.104774Z","iopub.status.idle":"2024-12-14T19:52:37.192172Z","shell.execute_reply.started":"2024-12-14T19:52:37.104741Z","shell.execute_reply":"2024-12-14T19:52:37.191034Z"}},"outputs":[{"name":"stdout","text":"GPU available\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"IMAGE_WIDTH = 128\nIMAGE_HEIGHT = 64","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T19:52:40.420583Z","iopub.execute_input":"2024-12-14T19:52:40.420925Z","iopub.status.idle":"2024-12-14T19:52:40.425224Z","shell.execute_reply.started":"2024-12-14T19:52:40.420895Z","shell.execute_reply":"2024-12-14T19:52:40.424244Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### encode_label_from_label_map\n\n- **Input**:  \n  - `label` (np.ndarray): A color image (H, W, 3) representing segmentation labels.  \n  - `label_map` (Dict): A dictionary mapping class names to their corresponding RGB colors.  \n- **Output**:  \n  - `np.ndarray`: A one-hot encoded mask of shape (H, W, n_classes).  \n- **Usage**: Converts a color-coded label into a one-hot encoded mask for semantic segmentation.  \n\n\n### decode_mask_from_color_map\n\n- **Input**:  \n  - `mask` (np.ndarray or torch.Tensor): A one-hot encoded mask of shape (H, W, n_classes).  \n  - `color_map` (Dict): A dictionary mapping class names to their corresponding RGB colors.  \n- **Output**:  \n  - `np.ndarray`: A decoded color image of shape (H, W, 3).  \n- **Usage**: Converts a one-hot encoded mask back into a color-coded label for visualization.  ","metadata":{}},{"cell_type":"code","source":"def encode_label_from_label_map(label: np.ndarray, label_map: Dict) -> np.ndarray:\n    def multiply_along_three_axes(a1, a2, a3):\n        return a1 * a2 * a3\n\n    n_classes = len(label_map.keys())\n    h, w = label.shape[:2]\n    mask = np.zeros((h, w, n_classes), dtype=np.float32)\n\n    for idx, cls in enumerate(label_map.keys()):\n        color = label_map[cls]\n        ij = label == color\n        if ij.ndim == 3:\n            ij = multiply_along_three_axes(*ij.transpose(2, 0, 1))\n        mask[ij, idx] = 1\n\n    return mask\n\ndef decode_mask_from_color_map(mask, color_map: Dict):\n    if isinstance(mask, torch.Tensor):\n        mask = mask.permute(1, 2, 0).numpy()\n\n    h, w = mask.shape[:2]\n    label = np.zeros((h, w, 3), dtype=np.uint8)\n\n    for idx, cls in enumerate(color_map.keys()):\n        color = color_map[cls]\n        label[mask[..., idx] == 1] = color\n\n    return label\n\n# Labels for decoding\nlabel_map_dict = {\n  'Terrain1': [0],\n  'Terrain2': [1],\n  'Terrain3': [2],\n  'Terrain4': [3],\n  'Terrain5': [4],\n}\n\n# Colors for plotting and encoding\ncolor_map_dict = {\n  'Terrain1': [0, 0, 0],\n  'Terrain2': [254, 0, 254],\n  'Terrain3': [0, 253, 0],\n  'Terrain4': [0, 0, 252],\n  'Terrain5': [250, 250, 250],\n\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:39:41.073458Z","iopub.execute_input":"2024-12-12T15:39:41.073797Z","iopub.status.idle":"2024-12-12T15:39:41.082333Z","shell.execute_reply.started":"2024-12-12T15:39:41.073768Z","shell.execute_reply":"2024-12-12T15:39:41.081441Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"# MarsSurface Class\n\n`__init__(self, mode: str, X, y, label_map_dict, color_map_dict, train_transforms, valid_transforms)`\nInitializes the dataset class for the Mars surface segmentation task.\n\n- **Input**:\n  - `mode` (str): Specifies the mode of the dataset, one of [\"train\", \"valid\", \"test\", \"debug\"].\n  - `X`: The input images (array or list-like structure).\n  - `y`: The corresponding labels for the images.\n  - `label_map_dict` (dict): A dictionary mapping class names to their labels.\n  - `color_map_dict` (dict): A dictionary mapping class names to their RGB color representation.\n  - `train_transforms` (callable): Transformations to be applied during training.\n  - `valid_transforms` (callable): Transformations to be applied during validation/testing.\n\n- **Output**: None\n\n\n`_read_data(self, item: int)`\nReads and preprocesses a single data point from the dataset.\n\n- **Input**:\n  - `item` (int): Index of the data point to read.\n\n- **Output**:\n  - `image` (np.ndarray): The preprocessed image.\n  - `label` (np.ndarray): The corresponding label encoded using `label_map_dict`.\n\n\n`_decode_label(self, label_map)`\nEncodes the label map into a one-hot encoded mask.\n\n- **Input**:\n  - `label_map` (np.ndarray): The label map for the given image.\n\n- **Output**:\n  - `mask` (np.ndarray): One-hot encoded mask of shape (H, W, n_classes).\n\n\n`__len__(self)`\nReturns the total number of samples in the dataset.\n\n- **Input**: None\n\n- **Output**:\n  - (int): Number of samples.\n\n\n`__getitem__(self, item: int)`\nFetches a data point, applies transformations, and prepares it for training or evaluation.\n\n- **Input**:\n  - `item` (int): Index of the data point.\n\n- **Output**:\n  - `image` (torch.Tensor): The transformed image tensor of shape (3, H, W).\n  - `mask` (torch.Tensor): The one-hot encoded mask tensor of shape (n_classes, H, W).\n  - `zero_mask` (torch.Tensor): A mask highlighting unannotated areas of shape (n_classes, H, W).\n  - `_label` (torch.Tensor): The decoded RGB mask tensor of shape (3, H, W).","metadata":{}},{"cell_type":"code","source":"class MarsSurface(Dataset):\n\n    def __init__(self, mode: str, X, y, label_map_dict, color_map_dict, train_transforms = train_transforms, valid_transforms = valid_transforms):\n        assert mode in [\"train\", \"valid\",\"test\", \"debug\"], \"Invalid value for self.mode, type 'train' or 'test'\"\n        self.label_map_dict = label_map_dict\n        self.color_map_dict = color_map_dict\n        self.mode = mode\n        self.transforms = train_transforms if self.mode in [\"train\", \"debug\"] else valid_transforms\n\n        self.img_size = [IMAGE_HEIGHT, IMAGE_WIDTH]\n        self.X = X\n        self.y = y\n\n    def _read_data(self, item: int):\n        image = self.X[item]\n        if image.max() > 1:\n            image = (image / 255).astype(\"float32\")\n        label = self._decode_label(self.y[item])\n\n        return image, label\n\n    def _decode_label(self, label_map):\n        return encode_label_from_label_map(label_map, self.label_map_dict)\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, item: int):\n        image, mask = self._read_data(item)\n        if image.ndim == 2:\n            image = np.repeat(image[..., np.newaxis], repeats=3, axis=2)\n\n        _label = decode_mask_from_color_map(mask, self.color_map_dict)\n\n        mask = torch.from_numpy(mask).permute(2, 0, 1).float()\n        image = torch.from_numpy(image).permute(2, 0, 1).float()\n        _label = torch.from_numpy(_label).permute(2, 0, 1).float()\n\n        # hide values on mask which aren't annotated\n        zero_mask = 1 - mask[0, ...]\n        zero_mask = torch.stack([zero_mask] * 5)\n\n        return image, mask, zero_mask, _label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:40:32.345768Z","iopub.execute_input":"2024-12-12T15:40:32.346384Z","iopub.status.idle":"2024-12-12T15:40:32.354966Z","shell.execute_reply.started":"2024-12-12T15:40:32.346351Z","shell.execute_reply":"2024-12-12T15:40:32.354013Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# Loads some semantic segmentation models with different encoder architectures to later perform ensemble.\n\nbase_path = '/kaggle/input/models'\n\nmodel_name = ['/mit_b2.pt', '/mit_b4.pt', '/mobileone_s4.pt']\n\nmodel_infer1 = smp.PSPNet(\n    encoder_name = 'mit_b2',\n    classes = 5,\n    encoder_weights = None,\n    in_channels = 3,\n    activation = None\n)\n\nmodel_infer1.load_state_dict(\n    torch.load(base_path + model_name[0], weights_only=True, map_location='cpu')\n)\n\nmodel_infer1.eval()\n\n\n\nmodel_infer2 = smp.PSPNet(\n    encoder_name = 'mit_b4',\n    classes = 5,\n    encoder_weights = None,\n    in_channels = 3,\n    activation = None\n)\n\nmodel_infer2.load_state_dict(\n    torch.load(base_path + model_name[1], weights_only=True, map_location='cpu')\n)\n\nmodel_infer2.eval()\n\n\n\nmodel_infer3 = smp.FPN(\n    encoder_name = 'mobileone_s4',\n    classes = 5,\n    encoder_weights = None,\n    in_channels = 3,\n    activation = None\n)\n\nmodel_infer3.load_state_dict(\n    torch.load(base_path + model_name[2], weights_only=True, map_location='cpu')\n)\n\nmodel_infer3.eval()\n\n\n\nmodels = [model_infer1, model_infer2, model_infer3]\n\nfor model in models:\n    infer_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model.to(infer_device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = np.load('/kaggle/input/mars-no-outliers/mars_no_outliers.npz')\ntraining_set = data['training_set']\n\nX = training_set[:, 0]\ny = training_set[:, 1]\n\nX_test = data['test_set']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:15:09.508643Z","iopub.execute_input":"2024-12-12T15:15:09.508994Z","iopub.status.idle":"2024-12-12T15:15:12.038993Z","shell.execute_reply.started":"2024-12-12T15:15:09.508962Z","shell.execute_reply":"2024-12-12T15:15:12.038303Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"### `create_dataset_training`\r\n\r\n### Purpose\r\nGenerates a processed training dataset by running ensemble model predictions on the input data (`X`, `y`) and saving the results along with their masks.\r\n\r\n---\r\n\r\n### Steps\r\n1. **Dataset and Dataloader**:  \r\n   Initializes a `MarsSurface` dataset in validation mode and processes it with a `DataLoader`.\r\n\r\n2. **Model Inference**:  \r\n   Runs predictions using an ensemble of models, scaling outputs to a 0–255 range. Predictions are concatenated and stored.\r\n\r\n3. **Save Results**:  \r\n   Saves the processed predictions (`final_dataset`) and ground truth masks (`final_masks`) as a compressed `.npz` file.\r\n\r\n---\r\n\r\n### Output\r\n- File: `ensembled_dataset_train.npz` containing:\r\n  - `dataset`: Predictions with shape `(N, C, H, W)`.\r\n  - `masks`: Masks wo_grad()` for inference.\r\n","metadata":{}},{"cell_type":"code","source":"def create_dataset_trianing(X, y):\n    \n    dataset = MarsSurface('valid', X, y, label_map_dict, color_map_dict)\n    \n    datatse_loader = DataLoader(\n        dataset,\n        batch_size = 1,\n        num_workers = 1,\n        shuffle = False,\n        drop_last = False,\n        pin_memory = True\n    )\n    \n    pbar = tqdm(enumerate(datatse_loader), total = len(datatse_loader), dynamic_ncols=True)\n\n    final_dataset = []\n    final_masks = []\n    \n    with torch.no_grad():\n        for i, (inputs, masks, zero_mask, label ) in pbar:\n            inputs = inputs.to(infer_device)\n            preds = []\n            for model in models:\n                out = model(inputs)\n                out = torch.argmax(out, dim = 1).unsqueeze(1)\n                out = (out / 4.0) * 255.0\n                preds.append(out)\n            \n            concatenated_predictions = torch.cat(preds, dim=1)\n            final_dataset.append(concatenated_predictions)\n            mask = torch.squeeze(masks, dim=0).numpy()\n            mask = np.argmax(mask, axis=0)\n            final_masks.append(mask)\n    \n    final_dataset = np.array([tensor.cpu().numpy() if isinstance(tensor, torch.Tensor) else tensor for tensor in final_dataset])\n    final_masks = np.array([mask.cpu().numpy() if isinstance(mask, torch.Tensor) else mask for mask in final_masks])\n    \n    final_dataset = np.array(final_dataset)  # Shape: (N, C, H, W)\n    final_masks = np.array(final_masks) # Shape: (N, H, W)\n    np.savez('ensembled_dataset_train.npz', dataset = final_dataset, masks = final_masks)\n    \n    print('Training dataset created')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:22:09.140480Z","iopub.execute_input":"2024-12-12T15:22:09.141226Z","iopub.status.idle":"2024-12-12T15:22:09.148766Z","shell.execute_reply.started":"2024-12-12T15:22:09.141195Z","shell.execute_reply":"2024-12-12T15:22:09.147877Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Similar to create_dataset_testing(X, y) but without adding ground truth to the dataset.\ndef create_dataset_testing(X):\n    \n    dataset = MarsSurface('valid', X, X, label_map_dict, color_map_dict)\n    \n    datatse_loader = DataLoader(\n        dataset,\n        batch_size = 1,\n        num_worker = 1,\n        shuffle = False,\n        drop_last = False,\n        pin_memory = True,\n    )\n    \n    pbar = tqdm(enumerate(datatse_loader), total=len(datatse_loader), dynamic_ncols=True)\n    final_dataset = []\n    \n    with torch.no_grad():\n        for i, (inputs, masks, zero_mask, label ) in pbar:\n            inputs = inputs.to(infer_device)\n            preds = []\n            for model in models:\n                out = model(inputs)\n                out = torch.argmax(out, dim=1).unsqueeze(1)\n                out = (out / 4.0) * 255.0\n                preds.append(out)\n            \n            concatenated_predictions = torch.cat(preds, dim=1)\n            final_dataset.append(concatenated_predictions)\n    \n    final_dataset = np.array([tensor.cpu().numpy() if isinstance(tensor, torch.Tensor) else tensor for tensor in final_dataset])\n    np.savez('ensembled_dataset_testing.npz', dataset=final_dataset)\n    \n    print(\"Test dataset created\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:22:03.670775Z","iopub.execute_input":"2024-12-12T15:22:03.671420Z","iopub.status.idle":"2024-12-12T15:22:03.677981Z","shell.execute_reply.started":"2024-12-12T15:22:03.671387Z","shell.execute_reply":"2024-12-12T15:22:03.677098Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"create_dataset_trianing(X, y)\ncreate_dataset_testing(X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}